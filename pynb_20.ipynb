{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path1 = '/home/gs/DataScientist/planet'\n",
    "trainPath = '/train-tif'\n",
    "testPath = '/test-tif'\n",
    "\n",
    "VERBOSE_INTERVAL = 5000\n",
    "\n",
    "NUM_BINS = 64\n",
    "MAX_PIX_VAL = 65535\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definitions\n",
    "\n",
    "def getImageHistograms (filePath):\n",
    "    try:\n",
    "        img = io.imread(filePath)\n",
    "        r, g, b, nir = img[:, :, 0], img[:, :, 1], img[:, :, 2], img[:, :, 3]\n",
    "        hr, bins = np.histogram(r,NUM_BINS,[0, MAX_PIX_VAL])\n",
    "        hg, bins = np.histogram(g,NUM_BINS,[0, MAX_PIX_VAL])\n",
    "        hb, bins = np.histogram(b,NUM_BINS,[0, MAX_PIX_VAL])\n",
    "        hnir, bins = np.histogram(nir,NUM_BINS,[0, MAX_PIX_VAL])\n",
    "    except:\n",
    "        print ('  error reading file {}'.format(filePath))\n",
    "        hr = np.zeros(NUM_BINS)\n",
    "        hg = np.zeros(NUM_BINS)\n",
    "        hb = np.zeros(NUM_BINS)\n",
    "        hnir = np.zeros(NUM_BINS)\n",
    "        \n",
    "    return hr, hg, hb, hnir\n",
    "\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=2000):\n",
    "    param = {}\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param['eta'] = 0.01\n",
    "    param['max_depth'] = 8\n",
    "    param['silent'] = 1\n",
    "    param['eval_metric'] = \"logloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = 0.8\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20, verbose_eval = 50)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, verbose_eval = 50)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train lines read: 40479\n"
     ]
    }
   ],
   "source": [
    "# read Y_train\n",
    "\n",
    "try:\n",
    "    Y_train = pd.read_csv(path1+'/train.csv')\n",
    "except:\n",
    "    path1 = '/home/ec2-user/DataScientist/planet'\n",
    "    Y_train = pd.read_csv(path1+'/train.csv')\n",
    "\n",
    "print ('Y_train lines read: {}'.format(len(Y_train)))\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in Y_train['tags'].values])))\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "#print(label_map)\n",
    "#print\n",
    "#print(inv_label_map)\n",
    "\n",
    "Y_trainDict = {}\n",
    "for i, row in Y_train.iterrows():\n",
    "    name = row['image_name']\n",
    "    tags = row['tags']\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    Y_trainDict[name] = targets\n",
    "\n",
    "#print (Y_trainDict['train_0'])\n",
    "#print (Y_trainDict['train_1'])\n",
    "#print (Y_trainDict['train_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "/home/gs/DataScientist/planet/train-tif/*.tif\n",
      "  files read: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/external/tifffile/tifffile.py:2546: UserWarning: unpack: string size must be a multiple of element size\n",
      "  warnings.warn(\"unpack: %s\" % e)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  files read: 10000\n",
      "  files read: 15000\n",
      "  files read: 20000\n",
      "  error readinf file /home/gs/DataScientist/planet/train-tif/train_28173.tif\n",
      "  error readinf file /home/gs/DataScientist/planet/train-tif/train_18772.tif\n",
      "  files read: 25000\n",
      "  files read: 30000\n",
      "  files read: 35000\n",
      "  error readinf file /home/gs/DataScientist/planet/train-tif/train_5023.tif\n",
      "  files read: 40000\n",
      "X_train shape   : (40479, 256)\n",
      "Y_trainAll shape: (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "# read train images\n",
    "\n",
    "X_train = [] # arrays\n",
    "\n",
    "Y_trainAll = []\n",
    "X_train_id = []\n",
    "lines = 0\n",
    "\n",
    "print('Read train images')\n",
    "path = os.path.join(path1+trainPath, '*.tif')\n",
    "print (path)\n",
    "files = glob.glob(path)\n",
    "for fl in files:\n",
    "    lines += 1\n",
    "    if lines % VERBOSE_INTERVAL == 0:\n",
    "        print ('  files read: {}'.format(lines))\n",
    "    flbase = os.path.basename(fl)\n",
    "    a,b,c,d = getImageHistograms(fl)\n",
    "    r = np.concatenate((a, b, c, d), axis = 0)\n",
    "    X_train.append(r)\n",
    "    name = flbase.replace('.tif', '')\n",
    "    X_train_id.append(name)\n",
    "    Y_trainAll.append(Y_trainDict[name])\n",
    "\n",
    "\n",
    "Y_trainAll = pd.DataFrame(Y_trainAll)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "print ('X_train shape   : {}'.format(X_train.shape))\n",
    "print ('Y_trainAll shape: {}'.format(Y_trainAll.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test images\n",
      "/home/gs/DataScientist/planet/test-tif/*.tif\n",
      "  files read: 5000\n",
      "  files read: 10000\n",
      "  files read: 15000\n",
      "  files read: 20000\n",
      "  error readinf file /home/gs/DataScientist/planet/test-tif/test_17393.tif\n",
      "  files read: 25000\n",
      "  files read: 30000\n",
      "  files read: 35000\n",
      "  files read: 40000\n",
      "(40669, 256)\n"
     ]
    }
   ],
   "source": [
    "X_test = [] # arrays\n",
    "X_test_id = []\n",
    "lines = 0 \n",
    "\n",
    "print('Read test images')\n",
    "path = os.path.join(path1+testPath, '*.tif')\n",
    "print (path)\n",
    "files = glob.glob(path)\n",
    "for fl in files:\n",
    "    lines += 1\n",
    "    if lines % VERBOSE_INTERVAL == 0:\n",
    "        print ('  files read: {}'.format(lines))\n",
    "    flbase = os.path.basename(fl)\n",
    "    a,b,c,d = getImageHistograms(fl)\n",
    "    r = np.concatenate((a, b, c, d), axis = 0)\n",
    "    X_test.append(r)\n",
    "    name = flbase.replace('.tif', '')\n",
    "    X_test_id.append(name)\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "print (X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (X_train.head())\n",
    "#print (X_train_id[0])\n",
    "#print (Y_trainAll.head())\n",
    "#print (X_test.head())\n",
    "#print (X_test_id[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train / test / eval\n",
    "# to be deleted\n",
    "\n",
    "X_train, X_test = X_train[:80], X_train[80:]\n",
    "Y_trainAll, Y_testAll = Y_trainAll[:80], Y_trainAll[80:]\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (X_test.shape)\n",
    "print (Y_trainAll.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0]\ttrain-logloss:0.683392\ttest-logloss:0.683414\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 20 rounds.\n",
      "[50]\ttrain-logloss:0.363098\ttest-logloss:0.364062\n",
      "[100]\ttrain-logloss:0.211254\ttest-logloss:0.213039\n",
      "[150]\ttrain-logloss:0.129907\ttest-logloss:0.132962\n",
      "[200]\ttrain-logloss:0.083849\ttest-logloss:0.088359\n",
      "[250]\ttrain-logloss:0.056665\ttest-logloss:0.063028\n",
      "[300]\ttrain-logloss:0.040169\ttest-logloss:0.048574\n",
      "[350]\ttrain-logloss:0.029667\ttest-logloss:0.040331\n",
      "[400]\ttrain-logloss:0.022918\ttest-logloss:0.035726\n",
      "[450]\ttrain-logloss:0.018423\ttest-logloss:0.033254\n",
      "[500]\ttrain-logloss:0.015272\ttest-logloss:0.031978\n",
      "[550]\ttrain-logloss:0.013057\ttest-logloss:0.031335\n",
      "[600]\ttrain-logloss:0.011366\ttest-logloss:0.031146\n",
      "Stopping. Best iteration:\n",
      "[620]\ttrain-logloss:0.010811\ttest-logloss:0.031123\n",
      "\n",
      "[0]\ttrain-logloss:0.68344\ttest-logloss:0.683397\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 20 rounds.\n",
      "[50]\ttrain-logloss:0.364635\ttest-logloss:0.362805\n",
      "[100]\ttrain-logloss:0.213397\ttest-logloss:0.210573\n",
      "[150]\ttrain-logloss:0.132528\ttest-logloss:0.129296\n",
      "[200]\ttrain-logloss:0.086714\ttest-logloss:0.083649\n",
      "[250]\ttrain-logloss:0.059517\ttest-logloss:0.057379\n",
      "[300]\ttrain-logloss:0.042802\ttest-logloss:0.042058\n",
      "[350]\ttrain-logloss:0.03219\ttest-logloss:0.033077\n",
      "[400]\ttrain-logloss:0.025175\ttest-logloss:0.027769\n",
      "[450]\ttrain-logloss:0.020452\ttest-logloss:0.024658\n",
      "[500]\ttrain-logloss:0.017245\ttest-logloss:0.022797\n",
      "[550]\ttrain-logloss:0.014918\ttest-logloss:0.021712\n",
      "[600]\ttrain-logloss:0.01318\ttest-logloss:0.021111\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-db32fda3baa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunXGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#cv_scores.append(log_loss(val_y, preds))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(cv_scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-bcd1e43eccfe>\u001b[0m in \u001b[0;36mrunXGB\u001b[0;34m(train_X, train_y, test_X, test_y, feature_names, seed_val, num_rounds)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxgtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# xgb cross validation\n",
    "\n",
    "# TODO save number of rounds!\n",
    "\n",
    "for i in range(0,17):\n",
    "    print (i)\n",
    "    Y_train = Y_trainAll.ix[:,i]\n",
    "\n",
    "    kf = model_selection.KFold(n_splits=3, shuffle=True, random_state=2016)\n",
    "    for dev_index, val_index in kf.split(range(X_train.shape[0])):\n",
    "        dev_X, val_X = X_train.iloc[dev_index], X_train.iloc[val_index]\n",
    "        dev_y, val_y = Y_train.iloc[dev_index], Y_train.iloc[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        #cv_scores.append(log_loss(val_y, preds))\n",
    "        #print(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 0\n",
      "feature 1\n",
      "feature 2\n",
      "feature 3\n",
      "feature 4\n",
      "feature 5\n",
      "feature 6\n",
      "feature 7\n",
      "feature 8\n",
      "feature 9\n",
      "feature 10\n",
      "feature 11\n",
      "feature 12\n",
      "feature 13\n",
      "feature 14\n",
      "feature 15\n",
      "feature 16\n",
      "(40669, 17)\n"
     ]
    }
   ],
   "source": [
    "# xgboost predict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predsDF = pd.DataFrame()\n",
    "for i in range(0,17):\n",
    "    print ('feature ' + str(i))\n",
    "    Y_train = Y_trainAll.ix[:,i]\n",
    "    #print (Y_train.shape)\n",
    "    preds, model = runXGB(X_train, Y_train, X_test, num_rounds=800)\n",
    "    predsDF[i] = preds\n",
    "\n",
    "print (predsDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (predsDF.head())\n",
    "print (X_train_id[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40669, 17)\n",
      "['clear primary', 'clear primary', 'clear primary water', 'clear primary water', 'primary partly_cloudy']\n",
      "   image_name                   tags\n",
      "0  test_34045          clear primary\n",
      "1  test_32937          clear primary\n",
      "2  test_10537    clear primary water\n",
      "3  test_30945    clear primary water\n",
      "4  test_13470  primary partly_cloudy\n"
     ]
    }
   ],
   "source": [
    "# predsDF to prediction file\n",
    "\n",
    "def mapf (arr):\n",
    "    res = ''\n",
    "    for i in range(0,17):\n",
    "        if arr[i] > 0.5:\n",
    "            res += inv_label_map[i] + ' '\n",
    "    res = res.rstrip()\n",
    "    return res\n",
    "\n",
    "print(predsDF.shape)\n",
    "\n",
    "textResults = []\n",
    "\n",
    "for i, row in predsDF.iterrows():\n",
    "    #print (i)\n",
    "    #print (list(row))\n",
    "    textResults.append ( mapf( list (row)))\n",
    "    \n",
    "print (textResults[0:5])\n",
    "\n",
    "res = pd.DataFrame()\n",
    "res['image_name'] = X_test_id\n",
    "res['tags'] = textResults\n",
    "\n",
    "print (res.head())\n",
    "\n",
    "res.to_csv('SUB_20.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
