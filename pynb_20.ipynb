{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path1 = '/home/gs/DataScientist/planet'\n",
    "trainPath = '/train-tif-sample'\n",
    "testPath = '/test-tif'\n",
    "\n",
    "VERBOSE_INTERVAL = 50\n",
    "\n",
    "NUM_BINS = 32\n",
    "MAX_PIX_VAL = 65535\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definitions\n",
    "\n",
    "def getImageHistograms (filePath):\n",
    "    img = io.imread(filePath)\n",
    "    r, g, b, nir = img[:, :, 0], img[:, :, 1], img[:, :, 2], img[:, :, 3]\n",
    "    hr, bins = np.histogram(r,NUM_BINS,[0, MAX_PIX_VAL])\n",
    "    hg, bins = np.histogram(g,NUM_BINS,[0, MAX_PIX_VAL])\n",
    "    hb, bins = np.histogram(b,NUM_BINS,[0, MAX_PIX_VAL])\n",
    "    hnir, bins = np.histogram(nir,NUM_BINS,[0, MAX_PIX_VAL])\n",
    "    \n",
    "    return hr, hg, hb, hnir\n",
    "\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=2000):\n",
    "    param = {}\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param['eta'] = 0.02\n",
    "    param['max_depth'] = 6\n",
    "    param['silent'] = 1\n",
    "    param['eval_metric'] = \"logloss\"\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = 0.7\n",
    "    param['colsample_bytree'] = 0.7\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20, verbose_eval = 50)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, verbose_eval = 50)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train lines read: 40479\n"
     ]
    }
   ],
   "source": [
    "# read Y_train\n",
    "\n",
    "try:\n",
    "    Y_train = pd.read_csv(path1+'/train.csv')\n",
    "except:\n",
    "    path1 = '/home/ec2-user/DataScientist/planet'\n",
    "    Y_train = pd.read_csv(path1+'/train.csv')\n",
    "\n",
    "print ('Y_train lines read: {}'.format(len(Y_train)))\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in Y_train['tags'].values])))\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "#print(label_map)\n",
    "#print\n",
    "#print(inv_label_map)\n",
    "\n",
    "Y_trainDict = {}\n",
    "for i, row in Y_train.iterrows():\n",
    "    name = row['image_name']\n",
    "    tags = row['tags']\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    Y_trainDict[name] = targets\n",
    "\n",
    "#print (Y_trainDict['train_0'])\n",
    "#print (Y_trainDict['train_1'])\n",
    "#print (Y_trainDict['train_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "/home/gs/DataScientist/planet/train-tif-sample/*.tif\n",
      "  lines read: 50\n",
      "  lines read: 100\n",
      "X_train shape   : (100, 128)\n",
      "Y_trainAll shape: (100, 17)\n"
     ]
    }
   ],
   "source": [
    "# read train images\n",
    "\n",
    "X_train = [] # arrays\n",
    "Y_trainAll = []\n",
    "X_train_id = []\n",
    "lines = 0\n",
    "\n",
    "print('Read train images')\n",
    "path = os.path.join(path1+trainPath, '*.tif')\n",
    "print (path)\n",
    "files = glob.glob(path)\n",
    "for fl in files:\n",
    "    lines += 1\n",
    "    if lines % VERBOSE_INTERVAL == 0:\n",
    "        print ('  lines read: {}'.format(lines))\n",
    "    flbase = os.path.basename(fl)\n",
    "    a,b,c,d = getImageHistograms(fl)\n",
    "    r = np.concatenate((a, b, c, d), axis = 0)\n",
    "    X_train.append(r)\n",
    "    name = flbase.replace('.tif', '')\n",
    "    X_train_id.append(name)\n",
    "    Y_trainAll.append(Y_trainDict[name])\n",
    "\n",
    "\n",
    "Y_trainAll = pd.DataFrame(Y_trainAll)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "print ('X_train shape   : {}'.format(X_train.shape))\n",
    "print ('Y_trainAll shape: {}'.format(Y_trainAll.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 128)\n",
      "(20, 128)\n",
      "(20, 128)\n",
      "(80, 17)\n"
     ]
    }
   ],
   "source": [
    "# train / test / eval\n",
    "# to be deleted\n",
    "\n",
    "X_train, X_test = X_train[:80], X_train[80:]\n",
    "Y_trainAll, Y_testAll = Y_trainAll[:80], Y_trainAll[80:]\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (X_test.shape)\n",
    "print (Y_trainAll.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 0\n",
      "feature 1\n",
      "feature 2\n",
      "feature 3\n",
      "feature 4\n",
      "feature 5\n",
      "feature 6\n",
      "feature 7\n",
      "feature 8\n",
      "feature 9\n",
      "feature 10\n",
      "feature 11\n",
      "feature 12\n",
      "feature 13\n",
      "feature 14\n",
      "feature 15\n",
      "feature 16\n",
      "(20, 17)\n"
     ]
    }
   ],
   "source": [
    "# xgboost predict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predsDF = pd.DataFrame()\n",
    "for i in range(0,17):\n",
    "    print ('feature ' + str(i))\n",
    "    Y_train = Y_trainAll.ix[:,i]\n",
    "    #print (Y_train.shape)\n",
    "    preds, model = runXGB(X_train, Y_train, X_test, num_rounds=220)\n",
    "    predsDF[i] = preds\n",
    "\n",
    "print (predsDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 17)\n",
      "['clear primary', 'clear primary water', 'clear primary', 'clear primary agriculture', 'clear primary']\n"
     ]
    }
   ],
   "source": [
    "# predsDF to prediction file\n",
    "\n",
    "def mapf (arr):\n",
    "    res = ''\n",
    "    for i in range(0,17):\n",
    "        if arr[i] > 0.5:\n",
    "            res += inv_label_map[i] + ' '\n",
    "    res = res.rstrip()\n",
    "    return res\n",
    "\n",
    "print(predsDF.shape)\n",
    "\n",
    "textResults = []\n",
    "\n",
    "for i, row in predsDF.iterrows():\n",
    "    #print (i)\n",
    "    #print (list(row))\n",
    "    textResults.append ( mapf( list (row)))\n",
    "    \n",
    "print (textResults[0:5])\n",
    "    \n",
    "# TODO / zip?\n",
    "\n",
    "# get test ids\n",
    "\n",
    "# write sub file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# xgb cross validation\n",
    "\n",
    "for i in range(0,17):\n",
    "    print (i)\n",
    "    Y_train = Y_trainAll.ix[:,i]\n",
    "\n",
    "    kf = model_selection.KFold(n_splits=3, shuffle=True, random_state=2016)\n",
    "    for dev_index, val_index in kf.split(range(X_train.shape[0])):\n",
    "        dev_X, val_X = X_train.iloc[dev_index], X_train.iloc[val_index]\n",
    "        dev_y, val_y = Y_train.iloc[dev_index], Y_train.iloc[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        #cv_scores.append(log_loss(val_y, preds))\n",
    "        #print(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
