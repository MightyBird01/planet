{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named keras.models",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5fa3465a464c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named keras.models"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1984)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import skimage\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import __version__ as keras_version\n",
    "from collections import Counter\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path1 = '/home/gs/DataScientist/planet'\n",
    "trainPath = '/train-tif-64'\n",
    "testPath = '/test-tif-64'\n",
    "\n",
    "RESIZE = True\n",
    "PIC_SIZE = 16\n",
    "PIC_DEPTH = 7\n",
    "\n",
    "def addChannels (i1):\n",
    "    r = i1[:,:,0]\n",
    "    g = i1[:,:,1]\n",
    "    b = i1[:,:,2]\n",
    "    nir = i1[:,:,3]\n",
    "    evi = 2.5 * (nir - r) / (nir + 6 * r - 7.5 * b + 1)\n",
    "    ndvi = (nir - r) / (nir.astype('float') + r)\n",
    "    arvi = (nir - (2 * r - b)) / (nir.astype('float') + (2 * r + b) )\n",
    "    res = np.dstack((i1, evi,ndvi,arvi))\n",
    "    return(res)\n",
    "\n",
    "def resizeImage (img):\n",
    "    img = transform.resize(img, (PIC_SIZE, PIC_SIZE))\n",
    "    return (img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read Y_train\n",
    "\n",
    "try:\n",
    "    Y_train = pd.read_csv(path1+'/train.csv')\n",
    "except:\n",
    "    path1 = '/home/ec2-user/DataScientist/planet'\n",
    "    Y_train = pd.read_csv(path1+'/train.csv')\n",
    "\n",
    "print (Y_train[0:5])\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in Y_train['tags'].values])))\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "print(label_map)\n",
    "print\n",
    "print(inv_label_map)\n",
    "\n",
    "Y_trainDict = {}\n",
    "for i, row in Y_train.iterrows():\n",
    "    name = row['image_name']\n",
    "    tags = row['tags']\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    Y_trainDict[name] = targets\n",
    "\n",
    "print (Y_trainDict['train_0'])\n",
    "print (Y_trainDict['train_1'])\n",
    "print (Y_trainDict['train_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getImage(path):\n",
    "    img = io.imread(path)\n",
    "    return img\n",
    "\n",
    "def load_train():\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_train_id = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    path = os.path.join(path1+trainPath, '*.tif')\n",
    "    print (path)\n",
    "    files = glob.glob(path)\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = getImage(fl)\n",
    "        if RESIZE == True:\n",
    "            img = resizeImage(img)\n",
    "        img = addChannels(img)\n",
    "        X_train.append(img)\n",
    "        name = flbase.replace('.tif', '')\n",
    "        X_train_id.append(name)\n",
    "        Y_train.append(Y_trainDict[name])\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train,X_train_id, Y_train\n",
    "\n",
    "def load_test():\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read test images')\n",
    "    path = os.path.join(path1+testPath, '*.tif')\n",
    "    print (path)\n",
    "    files = glob.glob(path)\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = getImage(fl)\n",
    "        if RESIZE == True:\n",
    "            img = resizeImage(img)\n",
    "        img = addChannels(img)\n",
    "        X_test.append(img)\n",
    "        name = flbase.replace('.tif', '')\n",
    "        X_test_id.append(name)\n",
    "\n",
    "    print('Read test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_test, X_test_id\n",
    "\n",
    "def mapf (arr):\n",
    "    res = ''\n",
    "    for i in range(0,17):\n",
    "        if arr[i] > 0.2:\n",
    "            res += inv_label_map[i] + ' '\n",
    "    res = res.rstrip()\n",
    "    return res\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_train_id, Y_train = load_train()\n",
    "print (len(X_train), len(X_train_id))\n",
    "print(X_train_id[0:5])\n",
    "print(X_train[0].shape)\n",
    "print(Y_train[0])\n",
    "print(Y_train[1])\n",
    "\n",
    "X_test, X_test_id = load_test()\n",
    "print (len(X_test), len(X_test_id))\n",
    "print(X_test_id[0:5])\n",
    "print(X_test[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print ('convert...')\n",
    "Y_train = np.array(Y_train, np.uint8)\n",
    "X_train = np.array(X_train, np.float16)\n",
    "X_test = np.array(X_test, np.float16) \n",
    "\n",
    "print ('normalize...')\n",
    "for i in range(0,7):\n",
    "    mi = np.min( np.min(X_train[:,:,:,i]), np.min(X_test[:,:,:,i]) )\n",
    "    ma = np.max( np.max(X_train[:,:,:,i]), np.max(X_test[:,:,:,i]) )\n",
    "    X_train[:,:,:,i] = (X_train[:,:,:,i] - mi) / (ma - mi)\n",
    "    X_test[:,:,:,i]  = (X_test[:,:,:,i] - mi) / (ma - mi)\n",
    "\n",
    "print ('train')\n",
    "print (np.min(X_train))\n",
    "print (np.mean(X_train))\n",
    "print (np.max(X_train))\n",
    "    \n",
    "print ('test')\n",
    "print (np.min(X_test))\n",
    "print (np.mean(X_test))\n",
    "print (np.max(X_test))\n",
    "    \n",
    "    \n",
    "print ('shapes')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train / use larger split value for predictions, more epochs\n",
    "\n",
    "split = 35000\n",
    "x_train, x_valid, y_train, y_valid = X_train[:split], X_train[split:], Y_train[:split], Y_train[split:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(PIC_SIZE, PIC_SIZE, PIC_DEPTH)))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(128, (5, 5), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid, y_valid))\n",
    "          \n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "p_valid = model.predict(x_valid, batch_size=128)\n",
    "#print(y_valid)\n",
    "#print(p_valid)\n",
    "print(fbeta_score(y_valid, np.array(p_valid) > 0.5, beta=2, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "preds = model.predict(X_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# X_test_id, preds -> submission\n",
    "predsText = []\n",
    "for e in preds:\n",
    "    predsText.append(mapf(e))\n",
    "print (predsText[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#image_name,tags\n",
    "#test_0,primary clear agriculture road water\n",
    "\n",
    "subName = path1 + '/SUB_04_64pix_xxep.csv'\n",
    "f = open(subName, 'w')\n",
    "f.write('image_name,tags\\n')\n",
    "for i in range(0,len(predsText)):\n",
    "    f.write(X_test_id[i]+','+predsText[i]+'\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print (type(preds))\n",
    "raw = pd.DataFrame(preds)\n",
    "raw['id'] = X_test_id\n",
    "print (raw.head())\n",
    "raw.to_csv('RAW_04_64px_xxep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
